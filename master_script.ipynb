{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\miniconda3\\lib\\site-packages\\nilearn\\datasets\\__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "import random\n",
    "import os\n",
    "\n",
    "import decoding\n",
    "from savingOutputs import *\n",
    "from loadData import *\n",
    "from masks import *\n",
    "from decoding import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "classes = ['Up', 'Down', 'Right', 'Left']\n",
    "nb_runs = 12\n",
    "length = nb_runs * len(classes)\n",
    "subjects_ids = range(1, 24)  # TODO modify this to get all subjects (here we only have 1 for the example)\n",
    "n_subjects = len(subjects_ids)\n",
    "n_perms = 1000\n",
    "class_labels = [\"\"] * (2 * length)\n",
    "for i in range(length * 2):\n",
    "    class_labels[i] = classes[(i // nb_runs) % len(classes)]\n",
    "labels = dict()\n",
    "labels[\"vis\"] = np.array(class_labels[:length])\n",
    "labels[\"aud\"] = np.array(class_labels[length:])\n",
    "labels_same = labels[\"vis\"]\n",
    "\n",
    "classical_tasks_regions = [([\"vis\"], [\"V5_R\", \"V5_L\"]),\n",
    "                           ([\"aud\"], [\"PT_R\", \"PT_L\"]),\n",
    "                           ([\"aud\"], [\"V5_R\", \"V5_L\"])]\n",
    "\n",
    "cross_modal_task_regions = [([\"vis\", \"aud\"], [\"V5_R\", \"V5_L\"])]\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "classifier = sklearn.svm.SVC(C = 1, kernel = 'linear', random_state=SEED)  # other parameters are default parameters\n",
    "pipeline = Pipeline([('std', scaler), ('svm', classifier)])\n",
    "decoder = Decoder(n_perm=n_perms, model=pipeline, n_classes=len(classes), n_splits=nb_runs, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_perms = [dict() for _ in subjects_ids]\n",
    "maps_masked = [dict() for _ in subjects_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done for subject 1/23\n",
      "Loading done for subject 2/23\n",
      "Loading done for subject 3/23\n",
      "Loading done for subject 4/23\n",
      "Loading done for subject 5/23\n",
      "Loading done for subject 6/23\n",
      "Loading done for subject 7/23\n",
      "Loading done for subject 8/23\n",
      "Loading done for subject 9/23\n",
      "Loading done for subject 10/23\n",
      "Loading done for subject 11/23\n",
      "Loading done for subject 12/23\n",
      "Loading done for subject 13/23\n",
      "Loading done for subject 14/23\n",
      "Loading done for subject 15/23\n",
      "Loading done for subject 16/23\n",
      "Loading done for subject 17/23\n",
      "Loading done for subject 18/23\n",
      "Loading done for subject 19/23\n",
      "Loading done for subject 20/23\n",
      "Loading done for subject 21/23\n",
      "Loading done for subject 22/23\n",
      "Loading done for subject 23/23\n"
     ]
    }
   ],
   "source": [
    "for i, subj_id in enumerate(subjects_ids):\n",
    "    t_maps, beta_maps = get_maps([subj_id])\n",
    "    masks = get_masks([subj_id], plot=False)\n",
    "    maps = apply_mask_to_maps(t_maps, masks)\n",
    "    maps_masked[i][\"vis\"] = get_part_of_maps(maps, 0, length)  # maps acquired for the vision experiment\n",
    "    maps_masked[i][\"aud\"] = get_part_of_maps(maps, length, 2 * length)  # maps acquired for the audition experiment\n",
    "    del t_maps ; del beta_maps ; del masks  # to relieve memory\n",
    "    print(\"Loading done for subject \"+str(subj_id)+\"/\"+str(n_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def average_dicos(dicos_):\n",
    "    dico = dict()\n",
    "    for key in dicos_[0]:\n",
    "        dico[key] = np.mean([dic[key] for dic in dicos_])\n",
    "\n",
    "    return dico"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Within-modality decoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = [dict() for _ in subjects_ids]\n",
    "p_values = [dict() for _ in subjects_ids]\n",
    "for i, subj_id in enumerate(subjects_ids):\n",
    "    # within-modality decoding : training on a task and decoding on other samples from same task\n",
    "    for tasks, regions in classical_tasks_regions:\n",
    "        cv_sc, p_val, scores_perm = decoder.classify_tasks_regions(maps_masked[i], labels, tasks, regions)\n",
    "        cv_scores[i].update(cv_sc)\n",
    "        p_values[i].update(p_val)\n",
    "        scores_perms[i].update(scores_perm)\n",
    "    print(\"Within-modality decoding done for subject \"+str(subj_id)+\"/\"+str(n_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute groups results\n",
    "within_modality_group_results = average_dicos(cv_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross-modal decoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_scores = [dict() for _ in subjects_ids]\n",
    "p_values = [dict() for _ in subjects_ids]\n",
    "for i, subj_id in enumerate(subjects_ids):\n",
    "    # cross-modal decoding : training on a task and decoding on samples from another task\n",
    "    for tasks, regions in cross_modal_task_regions:\n",
    "        scores_cross_mod = decoder.cross_modal_decoding(maps_masked[i], labels, tasks, regions)\n",
    "        cv_scores[i].update(scores_cross_mod)\n",
    "\n",
    "    print(\"Cross-modal decoding done for subject \"+str(subj_id)+\"/\"+str(n_subjects))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute groups results\n",
    "cross_modality_group_results = average_dicos(cv_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bootstrapping to assess group-level significance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 0 done\n",
      "subject 1 done\n",
      "subject 2 done\n",
      "subject 3 done\n",
      "subject 4 done\n",
      "subject 5 done\n",
      "subject 6 done\n",
      "subject 7 done\n",
      "subject 8 done\n",
      "subject 9 done\n",
      "subject 10 done\n",
      "subject 11 done\n",
      "subject 12 done\n",
      "subject 13 done\n",
      "subject 14 done\n",
      "subject 15 done\n",
      "subject 16 done\n",
      "subject 17 done\n",
      "subject 18 done\n",
      "subject 19 done\n",
      "subject 20 done\n",
      "subject 21 done\n",
      "subject 22 done\n",
      "Running models done in 308.77601075172424 seconds\n",
      "Creating distribution done in 1640972830.386041 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "n_bootstrap = 100_000\n",
    "n_single_perm = 100\n",
    "\n",
    "# 1. produce the 100 permuted datasets for each subject, and compute scores\n",
    "scores_100_Perm = [None]*n_subjects\n",
    "for i in range(n_subjects):\n",
    "    labels_shuffled = decoder.produce_permuted_labels(labels_same, n_single_perm) # repeating for each subject, such that we don't obtain same permutations\n",
    "    scores_dicts = [dict() for _ in range(n_single_perm)]\n",
    "    for j in range(n_single_perm) :\n",
    "        labels_dico = {\"vis\":labels_shuffled[j],\"aud\":labels_shuffled[j]}\n",
    "        for tasks, regions in classical_tasks_regions :\n",
    "            cv_sc,_,_ = decoder.classify_tasks_regions(maps_masked[i], labels_dico, tasks, regions, do_pval=False)\n",
    "            scores_dicts[j].update(cv_sc)\n",
    "\n",
    "    scores_100_Perm[i] = scores_dicts\n",
    "    print(\"subject \"+str(i)+\" done\")\n",
    "\n",
    "intermed_time = time.time()-start_time\n",
    "print(\"Running models done in \"+str(intermed_time)+\" seconds\")\n",
    "\n",
    "# 2. select randomly 100 000 times a score from each subject\n",
    "scores_bootstrap = [None]*n_bootstrap\n",
    "for i in range(n_bootstrap) :\n",
    "    dicos = [dict() for _ in range(n_subjects)]\n",
    "    for j in range(n_subjects) :\n",
    "        dicos[j] = scores_100_Perm[j][random.randint(0,n_single_perm-1)]\n",
    "    scores_bootstrap[i] = average_dicos(dicos)\n",
    "    if i%10_000 == 0 :\n",
    "        print(\"iteration n° \"+str(i))\n",
    "\n",
    "end_time = time.time() - intermed_time\n",
    "print(\"Creating distribution done in \"+str(end_time)+\" seconds\")\n",
    "\n",
    "# 3. compare with our obtained result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directory(\"out\")\n",
    "save_dicts(\"cv_scores.csv\", cv_scores, list(cv_scores[0].keys()), subjects_ids)\n",
    "save_dicts(\"p_values.csv\", p_values, list(p_values[0].keys()), subjects_ids)\n",
    "save_dicts_perms(\"scores_perms.csv\", scores_perms, subjects_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "save_dicts(\"bootstraps.csv\", scores_bootstrap, list(scores_bootstrap[0].keys()),range(n_bootstrap))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results (from files of saved results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt_directory = \"plots\"\n",
    "create_directory(plt_directory)\n",
    "plotter = Plotter(plt_directory, subjects_ids)\n",
    "plotter.plot_cv_pval(\"out/cv_scores.csv\", \"cv score\", plotter.cv_scores_dir, chance_level = True)\n",
    "plotter.plot_cv_pval(\"out/p_values.csv\", \"p-value\", plotter.p_values_dir)\n",
    "plotter.plot_perms_scores(\"out/scores_perms.csv\", n_perms)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizing differences between audition and vision in the voxels of a ROI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "region = \"V5_R\"\n",
    "colors = [\"red\",\"tomato\",\"coral\",\"orange\",\"deepskyblue\",\"cyan\",\"blue\",\"royalblue\"]\n",
    "n_voxels = maps_masked[0][\"vis\"][0][region].shape[1]\n",
    "mean_aud = dict()\n",
    "mean_vis = dict()\n",
    "\n",
    "for cla in classes :\n",
    "    mean_aud[cla] = np.zeros(n_voxels)\n",
    "    mean_vis[cla] = np.zeros(n_voxels)\n",
    "\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    for j, cla in enumerate(classes) :\n",
    "        mean_vis[cla] += np.mean(maps_masked[i][\"vis\"][0][region][j*12:(j+1)*12],axis=0)/n_subjects\n",
    "        mean_aud[cla] += np.mean(maps_masked[i][\"aud\"][0][region][j*12:(j+1)*12],axis=0)/n_subjects\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "idx = 0\n",
    "for cla in classes :\n",
    "    plt.plot(range(n_voxels), mean_vis[cla], label = \"vis - \"+cla, color = colors[idx])\n",
    "    idx += 1\n",
    "\n",
    "for cla in classes :\n",
    "    plt.plot(range(n_voxels), mean_aud[cla], label = \"aud - \"+cla, color = colors[idx])\n",
    "    idx += 1\n",
    "\n",
    "plt.xlabel(\"voxel id\")\n",
    "plt.ylabel(\"intensity\")\n",
    "plt.title(\"Average voxel intensities for right V5\")\n",
    "plt.legend()\n",
    "plt.savefig(\"plots/why_normalize_cross_modal.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}