{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import skelm\n",
    "import sklearn.linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from saving_outputs import *\n",
    "from load_data import *\n",
    "from masks import *\n",
    "from decoding import *\n",
    "from plots import *\n",
    "from utility import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_who = \"our\"   # 2 possibilities : \"mohameds\" or \"our\"\n",
    "voxel_size = \"3\" # 2 possibilities : \"2\" or \"3\"\n",
    "radius_mask = \"10\" # [mm] from 5 to 11\n",
    "use_t_maps = True # use t-maps or beta-maps\n",
    "correction = \"_Tcorrected\" # a t-value has been used to create ROIs or no,\n",
    "use_pca = False # use PCA or not\n",
    "components_pca = 20 # number of components to keep in PCA\n",
    "use_k_selector = False # use k-selector or not\n",
    "use_rfe = False # use RFE or not\n",
    "features_rfe = 25 # number of features to keep in RFE\n",
    "\n",
    "maps_folder=\"brain_maps/\"+from_who+\"_maps\"+\"_\"+voxel_size\n",
    "masks_folder=\"masks/\"+from_who+\"_masks\"+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "classes = ['Up', 'Down', 'Right', 'Left']\n",
    "nb_runs = 12\n",
    "labels = {'vis' : np.array(classes*nb_runs), 'aud' : np.array(classes*nb_runs)}\n",
    "labels_same = np.array(classes*nb_runs)\n",
    "subjects_ids = range(1, 24)\n",
    "n_subjects = len(subjects_ids)\n",
    "n_individual_perms = 1000\n",
    "\n",
    "within_modal_tasks_regions = [([\"vis\"], [\"V5_L\", \"V5_R\"]),\n",
    "                           ([\"vis\"], [\"PT_L\", \"PT_R\"]),\n",
    "                           ([\"aud\"], [\"V5_L\", \"V5_R\"]),\n",
    "                           ([\"aud\"], [\"PT_L\", \"PT_R\"])]\n",
    "\n",
    "cross_modal_tasks_regions = [([\"vis\", \"aud\"], [\"V5_L\", \"V5_R\"]),\n",
    "                            ([\"vis\", \"aud\"], [\"PT_L\", \"PT_R\"])]\n",
    "\n",
    "def k_selector(n_voxel):\n",
    "    return int(0.7*n_voxel)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif)\n",
    "\n",
    "classifiers = {\n",
    "    'svm':sklearn.svm.SVC(C=1, random_state=SEED),\n",
    "    #'LR':sklearn.linear_model.LogisticRegression(random_state=SEED),\n",
    "    #'KNN':sklearn.neighbors.KNeighborsClassifier(),\n",
    "    #'perceptron':sklearn.linear_model.Perceptron(random_state=SEED)\n",
    "    #'ELM':skelm.ELMClassifier(random_state=SEED, n_neurons=100, alpha=1),\n",
    "    }\n",
    "\n",
    "param_grids = {\n",
    "    'svm':{\n",
    "        'svm__C': [1],\n",
    "        #'svm__gamma': [1, 0.1],\n",
    "        'svm__kernel': ['linear']},\n",
    "\n",
    "    'LR':{\n",
    "        #'LR__C': [10**x for x in np.linspace(-3,3,num=20)]},\n",
    "        'LR__C': [0.05]},\n",
    "        'LR__max_iter': [1000],\n",
    "    'KNN':{\n",
    "        'KNN__n_neighbors': [1,3,5,10,20],\n",
    "        'KNN__weights':[\"uniform\", \"distance\"],\n",
    "    },\n",
    "    'perceptron':{\n",
    "        'perceptron__penalty':[\"l1\", \"l2\", \"elasticnet\", None],\n",
    "        'perceptron__max_iter':[100,300,1000],\n",
    "    },\n",
    "    'ELM':{\n",
    "        'ELM__n_neurons': [100,200,300,400,500],\n",
    "        'ELM__alpha': [0.1, 0.5, 1, 2, 5, 10, 20],\n",
    "    }\n",
    "}\n",
    "cv_scheme = list()\n",
    "for i in range(10):\n",
    "    full_idx = range(40)\n",
    "    idx_te = [i*4,i*4+1,i*4+2,i*4+3]\n",
    "    idx_tr = [x for x in full_idx if x not in idx_te]\n",
    "    tr_te_splits = [idx_tr, idx_te]\n",
    "    cv_scheme.append(tr_te_splits)\n",
    "\n",
    "models = dict()\n",
    "identity_transformer = FunctionTransformer(func=lambda x: x)\n",
    "for name in classifiers:\n",
    "    estimator_class = classifiers[name].__class__\n",
    "    params = classifiers[name].get_params()\n",
    "    #rfe_estimator = estimator_class().set_params(params) # not used at the moment\n",
    "    pipeline = Pipeline([('scaler', std_scaler),\n",
    "                         ('pca', (PCA(n_components=components_pca, random_state=SEED) if use_pca else identity_transformer)),\n",
    "                         ('kbest', (selector if use_k_selector else identity_transformer)),\n",
    "                         ('rfe', (RFE(sklearn.linear_model.LogisticRegression(random_state=SEED,C=0.05), n_features_to_select=features_rfe) if use_rfe else identity_transformer)),\n",
    "                         (name, classifiers[name])\n",
    "                         ])\n",
    "    GS = GridSearchCV(pipeline, param_grids[name], cv = cv_scheme, n_jobs = 4)\n",
    "    models[name] = GS\n",
    "    \n",
    "decoder = Decoder(n_perm=n_individual_perms, models=models, n_classes=len(classes), n_splits=nb_runs, seed=SEED, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maps_masked, masks_exist = load_full_data(subjects_ids, len(classes), nb_runs, maps_folder, masks_folder, is_from_mohamed=(from_who==\"mohameds\"), use_t_maps=use_t_maps)\n",
    "decoder.set_masks_exist(masks_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_voxels = maps_masked[0][\"vis\"][0][\"V5_L\"].shape[1]\n",
    "for name in classifiers:\n",
    "    if isinstance(decoder.models[name].estimator.steps[1][1], SelectKBest): \n",
    "        decoder.models[name].estimator.steps[1][1].set_params(k = k_selector(n_voxels))\n",
    "print(\"initially \"+str(n_voxels)+\" voxels, selected = \"+str(k_selector(n_voxels))+\" voxels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Within-modality decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrixes_within, val_scores_within = decoder.within_modality_decoding(maps_masked, labels, subjects_ids, within_modal_tasks_regions)\n",
    "confusion_matrixes_within = change_confusion_matrixes_org(confusion_matrixes_within, subjects_ids, models.keys())\n",
    "val_scores_within = change_confusion_matrixes_org(val_scores_within, subjects_ids, models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cross-modal decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrixes_cross, val_scores_cross = decoder.cross_modality_decoding(maps_masked, labels, subjects_ids, cross_modal_tasks_regions)\n",
    "confusion_matrixes_cross = change_confusion_matrixes_org(confusion_matrixes_cross, subjects_ids, models.keys())\n",
    "val_scores_cross = change_confusion_matrixes_org(val_scores_cross, subjects_ids, models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bootstrapping to assess group-level significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_single_perm = 50\n",
    "n_bootstrap = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "within_cf_100_perm = decoder.score_bootstrapped_permutations(n_single_perm, labels_same, within_modal_tasks_regions,maps_masked,n_subjects, within_modality=True)\n",
    "within_cf_100_perm = change_cfm_bootstrap_org(within_cf_100_perm, subjects_ids, models.keys(), n_single_perm)\n",
    "\n",
    "cross_cf_100_perm = decoder.score_bootstrapped_permutations(n_single_perm, labels_same, cross_modal_tasks_regions,maps_masked,n_subjects, within_modality=False)\n",
    "cross_cf_100_perm = change_cfm_bootstrap_org(cross_cf_100_perm, subjects_ids, models.keys(), n_single_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bootstrapped_distribution_cross = dict()\n",
    "bootstrapped_distribution_within = dict()\n",
    "for name in models.keys():\n",
    "    within_scores_100_perm = compute_accuracy_bootstrap(n_subjects, n_single_perm, within_cf_100_perm[name], len(classes))\n",
    "    bootstrapped_distribution_within[name] = compute_bootstrap_distribution(n_bootstrap, n_subjects, within_scores_100_perm, n_single_perm)\n",
    "\n",
    "    cross_scores_100_perm = compute_accuracy_bootstrap(n_subjects, n_single_perm, cross_cf_100_perm[name], len(classes))\n",
    "    bootstrapped_distribution_cross[name] = compute_bootstrap_distribution(n_bootstrap, n_subjects, cross_scores_100_perm, n_single_perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "type_maps = \"_t_maps_\" if use_t_maps else \"_beta_maps_\" \n",
    "out_directory = \"out/\"+from_who+type_maps\n",
    "\n",
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction + (\"_pca\"+str(components_pca) if use_pca else \"\") + (\"_\" + \"k_selector\" if use_k_selector else \"\")+ (\"_\" + \"rfe\"+str(features_rfe) if use_rfe else \"\")+\"/\"\n",
    "    create_directory(out_dir)\n",
    "    save_dicts(out_dir+\"masks_exist.csv\", masks_exist, list(masks_exist[0].keys()), subjects_ids)\n",
    "    \n",
    "    save_dicts(out_dir+\"confusion_matrixes_within.csv\", confusion_matrixes_within[name], list(confusion_matrixes_within[name][0].keys()), subjects_ids)\n",
    "    save_dicts(out_dir+\"validation_scores_within.csv\", val_scores_within[name], list(val_scores_within[name][0].keys()), subjects_ids)\n",
    "    acc_within = compute_metric(out_dir, subjects_ids, {'name' : 'accuracy', 'function':accuracy}, \"within\", masks_exist, len(classes), ret = True)\n",
    "\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'recall', 'function':recall}, \"within\", masks_exist, len(classes))\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'precision', 'function':precision}, \"within\", masks_exist, len(classes))\n",
    "\n",
    "    within_modality_group_results = average_dicos(acc_within)\n",
    "    save_dicts(out_dir+\"group_scores_within.csv\", [within_modality_group_results], list(within_modality_group_results.keys()), [0])\n",
    "\n",
    "    save_dicts(out_dir+\"confusion_matrixes_cross.csv\", confusion_matrixes_cross[name], list(confusion_matrixes_cross[name][0].keys()), subjects_ids)\n",
    "    save_dicts(out_dir+\"validation_scores_cross.csv\", val_scores_cross[name], list(val_scores_cross[name][0].keys()), subjects_ids)\n",
    "    acc_cross = compute_metric(out_dir, subjects_ids, {'name' : 'accuracy', 'function':accuracy}, \"cross\", masks_exist, len(classes), ret = True)\n",
    "    \n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'recall', 'function':recall}, \"cross\", masks_exist, len(classes))\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'precision', 'function':precision}, \"cross\", masks_exist, len(classes))\n",
    "\n",
    "    cross_modality_group_results = average_dicos(acc_cross)\n",
    "    save_dicts(out_dir+\"group_scores_cross.csv\", [cross_modality_group_results], list(cross_modality_group_results.keys()), [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask + (\"_\" + \"pca\" if use_pca else \"\") + (\"_\" + \"k_selector\" if use_k_selector else \"\")+(\"_\" + \"rfe\"+str(features_rfe) if use_rfe else \"\")+\"/\"\n",
    "    save_dicts(out_dir+\"accuracy_bootstraps_within.csv\", [bootstrapped_distribution_within[name]], list(bootstrapped_distribution_within[name][0].keys()), range(n_bootstrap))\n",
    "    save_dicts(out_dir+\"accuracy_bootstraps_cross.csv\", [bootstrapped_distribution_cross[name]], list(bootstrapped_distribution_cross[name][0].keys()), range(n_bootstrap))\n",
    "\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    bootstrap_df  = retrieve_bootstrap_metric(out_dir, \"accuracy\")\n",
    "    pvals = compute_p_val_bootstrap(bootstrap_df, cv_group_df)\n",
    "    save_dicts(out_dir+\"estimated_pval_bootstrap.csv\", [pvals], list(pvals.keys()), [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results (from files of saved results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type_maps = \"_t_maps_\" if use_t_maps else \"_beta_maps_\"\n",
    "out_directory = \"out/\"+from_who+type_maps#+\"_2tests_\"\n",
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction + (\"_\" + \"pca\"+str(components_pca) if use_pca else \"\") + (\"_\" + \"k_selector\" if use_k_selector else \"\")+(\"_\" + \"rfe\"+str(features_rfe) if use_rfe else \"\")+\"/\"\n",
    "    masks_exist = retrieve_masks_exist(out_dir)\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    cv_df = retrieve_cv_metric(out_dir, \"accuracy\")\n",
    "    cfm_df = retrieve_cv_matrixes(out_dir)\n",
    "    val_scores_df = retrieve_val_scores(out_dir)\n",
    "    pvals = retrieve_pvals(out_dir, default_keys=cv_df.columns)\n",
    "\n",
    "    plt_dir = \"plots/\"+from_who+type_maps+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction + (\"_\" + \"pca\"+str(components_pca) if use_pca else \"\") + (\"_\" + \"k_selector\" if use_k_selector else \"\")+(\"_\" + \"rfe\"+str(features_rfe) if use_rfe else \"\")\n",
    "    create_directory(plt_dir)\n",
    "    plotter = Plotter(plt_dir, subjects_ids)\n",
    "    plotter.plot_cv_score_with_points(cv_df, pvals, chance_level = True)\n",
    "    compute_accuracy_variance(out_dir, \"within\")\n",
    "    compute_accuracy_variance(out_dir, \"cross\")\n",
    "    #plotter.plot_validation_scores_hyper_param(val_scores_df, \"C\", param_grids[\"LR\"][\"LR__C\"], masks_exist, chance_level=True, log10_scale=True)\n",
    "\n",
    "    group_cfm = compute_group_confusion_matrix(cfm_df, subjects_ids)\n",
    "    plotter.plot_group_confusion_matrix(group_cfm, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+\"/\"\n",
    "    bootstrap_df  = retrieve_bootstrap_metric(out_dir, \"accuracy\")\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    pvals = retrieve_pvals(out_dir)\n",
    "    \n",
    "    plotter.plot_bootstrap(bootstrap_df, cv_group_df, pvals, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_ids = range(1,24)\n",
    "x = dict()\n",
    "type_maps = \"_t_maps_\" if use_t_maps else \"_beta_maps_\"\n",
    "x[\"2\"] = [81, 123, 179, 257, 389, 515]\n",
    "x[\"3\"] = [19, 33, 57, 81, 123, 171]\n",
    "acc_group_combination = dict()\n",
    "var_group_combination = dict()\n",
    "radiuses = range(5,11)\n",
    "voxel_sizes = [\"2\", \"3\"]\n",
    "\n",
    "for voxel_size in voxel_sizes:\n",
    "    acc_group_combination[voxel_size]= dict((radius,None) for radius in radiuses)\n",
    "    var_group_combination[voxel_size] = dict((radius,None) for radius in radiuses)\n",
    "    for radius in radiuses:\n",
    "        folder = \"out/our_\"+type_maps+str(voxel_size)+\"_radius=\"+str(radius)+\"_\"+str(classifiers[\"svm\"])+\"selecting_20.0%/\"\n",
    "        acc = retrieve_cv_metric(folder, \"group_scores\")\n",
    "        dfw = pd.read_csv(folder+\"var_within.csv\", index_col=0)\n",
    "        dfc = pd.read_csv(folder+\"var_cross.csv\", index_col=0)\n",
    "        df = pd.concat([dfw, dfc])\n",
    "        new_cols = df.index[1:]\n",
    "        temp_df = pd.DataFrame(columns=new_cols, index=[1], dtype=float)\n",
    "        temp_df[new_cols] = df[df.columns[0]].values[1:]\n",
    "\n",
    "        acc_group_combination[voxel_size][radius] = acc\n",
    "        var_group_combination[voxel_size][radius] = temp_df\n",
    "        #if not os.path.exists(folder+\"accuracy_cross.csv\"): os.rename(folder+\"cross_cross.csv\", folder+\"accuracy_cross.csv\")\n",
    "        #compute_accuracy_variance(folder, \"within\")\n",
    "        #compute_accuracy_variance(folder, \"cross\")\n",
    "\n",
    "colors = {\"2\":\"tab:green\",\"3\":\"tab:orange\"}\n",
    "plt_directory = \"plots/\"+from_who+\"_\"+type_maps+\"vsizes_radiuses_OK\"+str(classifiers[\"svm\"])+\"/\"\n",
    "create_directory(plt_directory)\n",
    "plotter = Plotter(plt_directory, subjects_ids)\n",
    "scores_var = dict()\n",
    "\n",
    "for i, analysis in enumerate(acc_group_combination[\"2\"][5]):\n",
    "    # # faire le plot\n",
    "    # for voxel_size in  voxel_sizes:\n",
    "    #      scores = [acc_group_combination[voxel_size][radius][analysis] for radius in radiuses]\n",
    "    # #     scores_var[analysis] = np.var(scores*100)\n",
    "    # #     print(analysis)\n",
    "    # #     print((max(scores)-min(scores))*100)\n",
    "    #      plt.plot(radiuses, scores, '-o', color = colors[voxel_size], label = voxel_size+\" mm\")\n",
    "    #      plt.axhline(0.25, color=\"gray\", alpha=0.5)\n",
    "    # title = plotter.generate_title(\"Accuracy\",analysis,0)\n",
    "    # plt.ylim(0.2,0.5)\n",
    "    # plotter.save(title+ \", depending on ROI radius\",\"\",\"mean accuracy\",\"radius [mm]\",legend=True)\n",
    "\n",
    "    # for voxel_size in  voxel_sizes:\n",
    "    #     scores = [acc_group_combination[voxel_size][radius][analysis] for radius in radiuses]\n",
    "    #     #n_voxels = list(map(k_selector, np.array(voxel_amounts[voxel_size])))\n",
    "    #     plt.plot(np.array(x[voxel_size]), scores, '-o', color = colors[voxel_size], label = voxel_size+\" mm\")\n",
    "    #     #print(\"number of voxels : \"+str(voxel_amounts[voxel_size]))\n",
    "    #     #print(\"number of voxels selected : \"+str(n_voxels))\n",
    "    #     plt.axhline(0.25, color=\"gray\", alpha=0.5)\n",
    "    # title = plotter.generate_title(\"Accuracy\",analysis,0)\n",
    "    # plt.ylim(0.2,0.5)\n",
    "    # plotter.save(title+\", depending on amount of voxels\",\"\",\"mean accuracy\",\"voxel amount\",legend=True)\n",
    "\n",
    "    for voxel_size in  voxel_sizes:\n",
    "        scores = [var_group_combination[voxel_size][radius][analysis] for radius in radiuses]\n",
    "        #n_voxels = list(map(k_selector, np.array(voxel_amounts[voxel_size])))\n",
    "        plt.plot(np.array(x[voxel_size]), scores, '-o', color = colors[voxel_size], label = voxel_size+\" mm\")\n",
    "        #print(\"number of voxels : \"+str(voxel_amounts[voxel_size]))\n",
    "        #print(\"number of voxels selected : \"+str(n_voxels))\n",
    "        #plt.axhline(0.25, color=\"gray\", alpha=0.5)\n",
    "    title = plotter.generate_title(\"Variance\",analysis,0)\n",
    "    plt.ylim(0, 0.014)\n",
    "    plotter.save(title+\", depending on amount of voxels\",\"\",\"accuracy variance\",\"voxel amount\",legend=True)\n",
    "\n",
    "# out_folders = list()\n",
    "# labels = list()\n",
    "# for kn in [\"2\", \"3\", \"5\"]:\n",
    "#     for sm in [\"15\", \"30\", \"50\"]:\n",
    "#         out_folders.append(\"out/our__t_maps_3_radius=10_SVC(C=1, random_state=0)smote\"+sm+\"kn\"+kn+\"/\")\n",
    "#         labels.append(\"s=\"+sm+\"k=\"+kn)\n",
    "\n",
    "# out_folders.append(\"out/our_3_radius=10_SVC(C=1, random_state=0)/\")\n",
    "# labels.append(\"no smote\")\n",
    "\n",
    "# print(out_folders)\n",
    "\n",
    "\n",
    "# plotter = Plotter(\"plots/comparing_smote_\"+\"_\".join(labels), subjects_ids)\n",
    "# plotter.plot_tests_scores_from_different_folders(out_folders, labels, \"SMOTE\", \"parameters\")\n",
    "# plotter.plot_accuracy_var_from_different_folders(out_folders, labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
