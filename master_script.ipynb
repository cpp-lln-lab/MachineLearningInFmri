{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\miniconda3\\lib\\site-packages\\nilearn\\datasets\\__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from saving_outputs import *\n",
    "from load_data import *\n",
    "from masks import *\n",
    "from decoding import *\n",
    "from plots import *\n",
    "from utility import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_who = \"our\"   # 2 possibilities : \"mohameds\" or \"our\"\n",
    "voxel_size = \"3\" # 2 possibilities : \"2\" or \"3\"\n",
    "radius_mask = \"10\" # [mm] from 5 to 11\n",
    "use_t_maps = True # use t-maps or beta-maps\n",
    "correction = \"_Tcorrected\" # a t-value has been used to create ROIs or no\n",
    "\n",
    "maps_folder=\"brain_maps/\"+from_who+\"_maps\"+\"_\"+voxel_size\n",
    "masks_folder=\"masks/\"+from_who+\"_masks\"+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "classes = ['Up', 'Down', 'Right', 'Left']\n",
    "nb_runs = 12\n",
    "labels = {'vis' : np.array(classes*nb_runs), 'aud' : np.array(classes*nb_runs)}\n",
    "labels_same = np.array(classes*nb_runs)\n",
    "subjects_ids = range(1, 24)\n",
    "n_subjects = len(subjects_ids)\n",
    "n_individual_perms = 1000\n",
    "\n",
    "within_modal_tasks_regions = [([\"vis\"], [\"V5_L\", \"V5_R\"]),\n",
    "                           ([\"vis\"], [\"PT_L\", \"PT_R\"]),\n",
    "                           ([\"aud\"], [\"V5_L\", \"V5_R\"]),\n",
    "                           ([\"aud\"], [\"PT_L\", \"PT_R\"])]\n",
    "\n",
    "cross_modal_tasks_regions = [([\"vis\", \"aud\"], [\"V5_L\", \"V5_R\"]),\n",
    "                            ([\"vis\", \"aud\"], [\"PT_L\", \"PT_R\"])]\n",
    "\n",
    "def k_selector(n_voxel):\n",
    "    return int(0.7*n_voxel)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif)\n",
    "\n",
    "classifiers = {\n",
    "    #'svm':sklearn.svm.SVC(kernel = 'linear', random_state=SEED),\n",
    "    'LR':sklearn.linear_model.LogisticRegression(random_state=SEED),\n",
    "    #'ELM':skelm.ELMClassifier(random_state=SEED, n_neurons=100, alpha=1),\n",
    "    }\n",
    "\n",
    "param_grids = {\n",
    "    'svm':{\n",
    "        #'svm__C': [10**x for x in np.linspace(-3,3,num=20)],\n",
    "        'svm__C': [1],\n",
    "        #'svm__gamma': [1, 0.1],\n",
    "        #'svm__kernel': ['linear','rbf','sigmoid']},\n",
    "    },\n",
    "    'LR':{\n",
    "        #'LR__C': [10**x for x in np.linspace(-3,3,num=20)]},\n",
    "        'LR__C': [1]},\n",
    "    'ELM':{},\n",
    "}\n",
    "cv_scheme = list()\n",
    "for i in range(11):\n",
    "    full_idx = range(44)\n",
    "    idx_te = [i*4,i*4+1,i*4+2,i*4+3]\n",
    "    idx_tr = [x for x in full_idx if x not in idx_te]\n",
    "    tr_te_splits = [idx_tr, idx_te]\n",
    "    cv_scheme.append(tr_te_splits)\n",
    "\n",
    "models = dict()\n",
    "for name in classifiers:\n",
    "    pipeline = Pipeline([('scaler', std_scaler),\n",
    "                         #('kbest', selector),\n",
    "                         (name, classifiers[name])])\n",
    "    GS = GridSearchCV(pipeline, param_grids[name], cv = cv_scheme,\n",
    "                      n_jobs = 4)\n",
    "    models[name] = GS\n",
    "    \n",
    "decoder = Decoder(n_perm=n_individual_perms, models=models, n_classes=len(classes), n_splits=nb_runs, seed=SEED, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maps_masked, masks_exist = load_full_data(subjects_ids, len(classes), nb_runs, maps_folder, masks_folder, is_from_mohamed=(from_who==\"mohameds\"), use_t_maps=use_t_maps)\n",
    "decoder.set_masks_exist(masks_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_voxels = maps_masked[0][\"vis\"][0][\"V5_L\"].shape[1]\n",
    "for name in classifiers:\n",
    "    if isinstance(decoder.models[name].estimator.steps[1][1], SelectKBest): \n",
    "        decoder.models[name].estimator.steps[1][1].set_params(k = k_selector(n_voxels))\n",
    "print(\"initially \"+str(n_voxels)+\" voxels, selected = \"+str(k_selector(n_voxels))+\" voxels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Within-modality decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrixes_within, val_scores_within = decoder.within_modality_decoding(maps_masked, labels, subjects_ids, within_modal_tasks_regions)\n",
    "confusion_matrixes_within = change_confusion_matrixes_org(confusion_matrixes_within, subjects_ids, models.keys())\n",
    "val_scores_within = change_confusion_matrixes_org(val_scores_within, subjects_ids, models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cross-modal decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1/23 done in 15.014223575592041 seconds\n",
      "subject 2/23 done in 31.930098295211792 seconds\n",
      "subject 3/23 done in 44.760886430740356 seconds\n",
      "subject 4/23 done in 58.48604106903076 seconds\n",
      "subject 5/23 done in 72.79776859283447 seconds\n",
      "subject 6/23 done in 90.60329699516296 seconds\n",
      "subject 7/23 done in 107.7555046081543 seconds\n",
      "subject 8/23 done in 123.09392213821411 seconds\n",
      "subject 9/23 done in 137.7036154270172 seconds\n",
      "subject 10/23 done in 151.54293632507324 seconds\n",
      "subject 11/23 done in 161.76932954788208 seconds\n",
      "subject 12/23 done in 171.84174180030823 seconds\n",
      "subject 13/23 done in 181.4036841392517 seconds\n",
      "subject 14/23 done in 194.59948325157166 seconds\n",
      "subject 15/23 done in 208.44287490844727 seconds\n",
      "subject 16/23 done in 222.70462369918823 seconds\n",
      "subject 17/23 done in 236.6583755016327 seconds\n",
      "subject 18/23 done in 250.68495321273804 seconds\n",
      "subject 19/23 done in 258.8027367591858 seconds\n",
      "subject 20/23 done in 272.2770321369171 seconds\n",
      "subject 21/23 done in 275.4774866104126 seconds\n",
      "subject 22/23 done in 289.5183479785919 seconds\n",
      "subject 23/23 done in 302.7973783016205 seconds\n",
      "done in 302.7973783016205 seconds\n"
     ]
    }
   ],
   "source": [
    "confusion_matrixes_cross, val_scores_cross = decoder.cross_modality_decoding(maps_masked, labels, subjects_ids, cross_modal_tasks_regions)\n",
    "confusion_matrixes_cross = change_confusion_matrixes_org(confusion_matrixes_cross, subjects_ids, models.keys())\n",
    "val_scores_cross = change_confusion_matrixes_org(val_scores_cross, subjects_ids, models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bootstrapping to assess group-level significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_single_perm = 50\n",
    "n_bootstrap = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "within_cf_100_perm = decoder.score_bootstrapped_permutations(n_single_perm, labels_same, within_modal_tasks_regions,maps_masked,n_subjects, within_modality=True)\n",
    "within_cf_100_perm = change_cfm_bootstrap_org(within_cf_100_perm, subjects_ids, models.keys(), n_single_perm)\n",
    "\n",
    "cross_cf_100_perm = decoder.score_bootstrapped_permutations(n_single_perm, labels_same, cross_modal_tasks_regions,maps_masked,n_subjects, within_modality=False)\n",
    "cross_cf_100_perm = change_cfm_bootstrap_org(cross_cf_100_perm, subjects_ids, models.keys(), n_single_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bootstrapped_distribution_cross = dict()\n",
    "bootstrapped_distribution_within = dict()\n",
    "for name in models.keys():\n",
    "    within_scores_100_perm = compute_accuracy_bootstrap(n_subjects, n_single_perm, within_cf_100_perm[name], len(classes))\n",
    "    bootstrapped_distribution_within[name] = compute_bootstrap_distribution(n_bootstrap, n_subjects, within_scores_100_perm, n_single_perm)\n",
    "\n",
    "    cross_scores_100_perm = compute_accuracy_bootstrap(n_subjects, n_single_perm, cross_cf_100_perm[name], len(classes))\n",
    "    bootstrapped_distribution_cross[name] = compute_bootstrap_distribution(n_bootstrap, n_subjects, cross_scores_100_perm, n_single_perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3079\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3080\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6680/3516683775.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mout_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mout_directory\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassifiers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"_\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mvoxel_size\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"_radius=\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mradius_mask\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mcorrection\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mcreate_directory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[0msave_dicts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_dir\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"masks_exist.csv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmasks_exist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmasks_exist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubjects_ids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[0msave_dicts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_dir\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"confusion_matrixes_within.csv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfusion_matrixes_within\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfusion_matrixes_within\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubjects_ids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3022\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3023\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3024\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3025\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3080\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3082\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3084\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "type_maps = \"_t_maps_\" if use_t_maps else \"_beta_maps_\"\n",
    "out_directory = \"out/\"+from_who+type_maps\n",
    "\n",
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction+\"/\"\n",
    "    create_directory(out_dir)\n",
    "    save_dicts(out_dir+\"masks_exist.csv\", masks_exist, list(masks_exist[0].keys()), subjects_ids)\n",
    "    \n",
    "    save_dicts(out_dir+\"confusion_matrixes_within.csv\", confusion_matrixes_within[name], list(confusion_matrixes_within[name][0].keys()), subjects_ids)\n",
    "    save_dicts(out_dir+\"validation_scores_within.csv\", val_scores_within[name], list(val_scores_within[name][0].keys()), subjects_ids)\n",
    "    acc_within = compute_metric(out_dir, subjects_ids, {'name' : 'accuracy', 'function':accuracy}, \"within\", masks_exist, len(classes), ret = True)\n",
    "\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'recall', 'function':recall}, \"within\", masks_exist, len(classes))\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'precision', 'function':precision}, \"within\", masks_exist, len(classes))\n",
    "\n",
    "    within_modality_group_results = average_dicos(acc_within)\n",
    "    save_dicts(out_dir+\"group_scores_within.csv\", [within_modality_group_results], list(within_modality_group_results.keys()), [0])\n",
    "\n",
    "    save_dicts(out_dir+\"confusion_matrixes_cross.csv\", confusion_matrixes_cross[name], list(confusion_matrixes_cross[name][0].keys()), subjects_ids)\n",
    "    save_dicts(out_dir+\"validation_scores_cross.csv\", val_scores_cross[name], list(val_scores_cross[name][0].keys()), subjects_ids)\n",
    "    acc_cross = compute_metric(out_dir, subjects_ids, {'name' : 'accuracy', 'function':accuracy}, \"cross\", masks_exist, len(classes), ret = True)\n",
    "    \n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'recall', 'function':recall}, \"cross\", masks_exist, len(classes))\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'precision', 'function':precision}, \"cross\", masks_exist, len(classes))\n",
    "\n",
    "    cross_modality_group_results = average_dicos(acc_cross)\n",
    "    save_dicts(out_dir+\"group_scores_cross.csv\", [cross_modality_group_results], list(cross_modality_group_results.keys()), [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+\"/\"\n",
    "    save_dicts(out_dir+\"accuracy_bootstraps_within.csv\", [bootstrapped_distribution_within[name]], list(bootstrapped_distribution_within[name][0].keys()), range(n_bootstrap))\n",
    "    save_dicts(out_dir+\"accuracy_bootstraps_cross.csv\", [bootstrapped_distribution_cross[name]], list(bootstrapped_distribution_cross[name][0].keys()), range(n_bootstrap))\n",
    "\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    bootstrap_df  = retrieve_bootstrap_metric(out_dir, \"accuracy\")\n",
    "    pvals = compute_p_val_bootstrap(bootstrap_df, cv_group_df)\n",
    "    save_dicts(out_dir+\"estimated_pval_bootstrap.csv\", [pvals], list(pvals.keys()), [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results (from files of saved results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No p-values found in directory : out/our_t_maps_LogisticRegression(random_state=0)_3_radius=10/_Tcorrected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1656x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_maps = \"_t_maps_\" if use_t_maps else \"_beta_maps_\"\n",
    "out_directory = \"out/\"+from_who+type_maps\n",
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+\"/\"+correction\n",
    "    masks_exist = retrieve_masks_exist(out_dir)\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    cv_df = retrieve_cv_metric(out_dir, \"accuracy\")\n",
    "    cfm_df = retrieve_cv_matrixes(out_dir)\n",
    "    val_scores_df = retrieve_val_scores(out_dir)\n",
    "    pvals = retrieve_pvals(out_dir, default_keys=cv_df.columns)\n",
    "\n",
    "    plt_dir = \"plots/\"+from_who+type_maps+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction\n",
    "    create_directory(plt_dir)\n",
    "    plotter = Plotter(plt_dir, subjects_ids)\n",
    "    plotter.plot_cv_score_with_points(cv_df, pvals, chance_level = True)\n",
    "    plotter.plot_validation_scores_hyper_param(val_scores_df, \"C\", param_grids[\"svm\"][\"svm__C\"], masks_exist, chance_level=True, log10_scale=True)\n",
    "\n",
    "    group_cfm = compute_group_confusion_matrix(cfm_df, subjects_ids)\n",
    "    plotter.plot_group_confusion_matrix(group_cfm, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+\"/\"\n",
    "    bootstrap_df  = retrieve_bootstrap_metric(out_dir, \"accuracy\")\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    pvals = retrieve_pvals(out_dir)\n",
    "    \n",
    "    plotter.plot_bootstrap(bootstrap_df, cv_group_df, pvals, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"out/our_t_maps_SVC(C=1, kernel='linear', random_state=0)_3_radius=10_Tcorrected/accuracy_within.csv\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6680/3236417496.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mclassifiers_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"SVM\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"LR\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"SVM corrected\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"LR corrected\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mplotter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPlotter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"plots/comparing_classifiers_\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"_\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassifiers_names\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msubjects_ids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mplotter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot_tests_scores_from_different_folders\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_folders\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclassifiers_names\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py\u001B[0m in \u001B[0;36mplot_tests_scores_from_different_folders\u001B[1;34m(self, folder_names, labels)\u001B[0m\n\u001B[0;32m    302\u001B[0m         \u001B[0mbig_cross_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    303\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfolder_names\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 304\u001B[1;33m             \u001B[0mcv_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mretrieve_cv_metric\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"accuracy\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    305\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    306\u001B[0m             \u001B[0mdf_within\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mverbose_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcv_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabels_within\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubject_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompare\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\load_data.py\u001B[0m in \u001B[0;36mretrieve_cv_metric\u001B[1;34m(out_directory, metric)\u001B[0m\n\u001B[0;32m     90\u001B[0m     \"\"\"\n\u001B[0;32m     91\u001B[0m     \u001B[1;31m# joining dataframes in prevision of plotting\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m     \u001B[0mcv_within_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_directory\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmetric\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"_within.csv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     93\u001B[0m     \u001B[0mcv_cross_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_directory\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmetric\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"_cross.csv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mcol\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcv_cross_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mcv_within_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv_cross_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 610\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    611\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    461\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 462\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    463\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    464\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    817\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    818\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 819\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    820\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1048\u001B[0m             )\n\u001B[0;32m   1049\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1050\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1051\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1052\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   1865\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1866\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1867\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1868\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1869\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m\"storage_options\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"encoding\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"memory_map\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"compression\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m   1360\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHanldes\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1361\u001B[0m         \"\"\"\n\u001B[1;32m-> 1362\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m   1363\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1364\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    640\u001B[0m                 \u001B[0merrors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"replace\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    641\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 642\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    643\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    644\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: \"out/our_t_maps_SVC(C=1, kernel='linear', random_state=0)_3_radius=10_Tcorrected/accuracy_within.csv\""
     ]
    }
   ],
   "source": [
    "subjects_ids = range(1,24)\n",
    "out_folders = [\"out/our_t_maps_SVC(C=1, kernel='linear', random_state=0)_3_radius=10_Tcorrected/\",\n",
    "               \"out/our_t_maps_LogisticRegression(random_state=0)_3_radius=10/\",\n",
    "               \"out/our_t_maps_SVC(C=1, kernel='linear', random_state=0)_3_radius=10/\",\n",
    "               \"out/our_t_maps_LogisticRegression(random_state=0)_3_radius=10_Tcorrected/\",\n",
    "               ]\n",
    "classifiers_names = [\"SVM\", \"LR\", \"SVM corrected\", \"LR corrected\"]\n",
    "plotter = Plotter(\"plots/comparing_classifiers_\"+\"_\".join(classifiers_names), subjects_ids)\n",
    "plotter.plot_tests_scores_from_different_folders(out_folders, classifiers_names, \"Comparing classifiers\", \"Classifier\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
