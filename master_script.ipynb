{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\miniconda3\\lib\\site-packages\\nilearn\\datasets\\__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from saving_outputs import *\n",
    "from load_data import *\n",
    "from masks import *\n",
    "from decoding import *\n",
    "from plots import *\n",
    "from utility import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_who = \"our\"   # 2 possibilities : \"mohameds\" or \"our\"\n",
    "voxel_size = \"3\" # 2 possibilities : \"2\" or \"3\"\n",
    "radius_mask = \"10\" # [mm] from 5 to 11\n",
    "use_t_maps = True # use t-maps or beta-maps\n",
    "correction = \"_Tcorrected\" # a t-value has been used to create ROIs or no\n",
    "\n",
    "maps_folder=\"brain_maps/\"+from_who+\"_maps\"+\"_\"+voxel_size\n",
    "masks_folder=\"masks/\"+from_who+\"_masks\"+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "classes = ['Up', 'Down', 'Right', 'Left']\n",
    "nb_runs = 12\n",
    "labels = {'vis' : np.array(classes*nb_runs), 'aud' : np.array(classes*nb_runs)}\n",
    "labels_same = np.array(classes*nb_runs)\n",
    "subjects_ids = range(1, 24)\n",
    "n_subjects = len(subjects_ids)\n",
    "n_individual_perms = 1000\n",
    "\n",
    "within_modal_tasks_regions = [([\"vis\"], [\"V5_L\", \"V5_R\"]),\n",
    "                           ([\"vis\"], [\"PT_L\", \"PT_R\"]),\n",
    "                           ([\"aud\"], [\"V5_L\", \"V5_R\"]),\n",
    "                           ([\"aud\"], [\"PT_L\", \"PT_R\"])]\n",
    "\n",
    "cross_modal_tasks_regions = [([\"vis\", \"aud\"], [\"V5_L\", \"V5_R\"]),\n",
    "                            ([\"vis\", \"aud\"], [\"PT_L\", \"PT_R\"])]\n",
    "\n",
    "def k_selector(n_voxel):\n",
    "    return int(0.7*n_voxel)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif)\n",
    "\n",
    "classifiers = {\n",
    "    'svm':sklearn.svm.SVC(random_state=SEED),\n",
    "    'LR':sklearn.linear_model.LogisticRegression(random_state=SEED),\n",
    "    'KNN':sklearn.neighbors.KNeighborsClassifier(),\n",
    "    'perceptron':sklearn.linear_model.Perceptron(random_state=SEED)\n",
    "    #'ELM':skelm.ELMClassifier(random_state=SEED, n_neurons=100, alpha=1),\n",
    "    }\n",
    "\n",
    "param_grids = {\n",
    "    'svm':{\n",
    "        'svm__C': [10**x for x in np.linspace(-3,3,num=20)],\n",
    "        #'svm__gamma': [1, 0.1],\n",
    "        'svm__kernel': ['linear','rbf','sigmoid']},\n",
    "\n",
    "    'LR':{\n",
    "        'LR__C': [10**x for x in np.linspace(-3,3,num=20)]},\n",
    "    'KNN':{\n",
    "        'KNN__n_neighbors': [1,3,5,10,20],\n",
    "        'KNN__weights':[\"uniform\", \"distance\"],\n",
    "    },\n",
    "    'perceptron':{\n",
    "        'perceptron__penalty':[\"l1\", \"l2\", \"elasticnet\", None],\n",
    "        'perceptron__max_iter':[100,300,1000],\n",
    "    }\n",
    "}\n",
    "cv_scheme = list()\n",
    "for i in range(11):\n",
    "    full_idx = range(44)\n",
    "    idx_te = [i*4,i*4+1,i*4+2,i*4+3]\n",
    "    idx_tr = [x for x in full_idx if x not in idx_te]\n",
    "    tr_te_splits = [idx_tr, idx_te]\n",
    "    cv_scheme.append(tr_te_splits)\n",
    "\n",
    "models = dict()\n",
    "for name in classifiers:\n",
    "    pipeline = Pipeline([('scaler', std_scaler),\n",
    "                         #('kbest', selector),\n",
    "                         (name, classifiers[name])])\n",
    "    GS = GridSearchCV(pipeline, param_grids[name], cv = cv_scheme,\n",
    "                      n_jobs = 4)\n",
    "    models[name] = GS\n",
    "    \n",
    "decoder = Decoder(n_perm=n_individual_perms, models=models, n_classes=len(classes), n_splits=nb_runs, seed=SEED, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maps_masked, masks_exist = load_full_data(subjects_ids, len(classes), nb_runs, maps_folder, masks_folder, is_from_mohamed=(from_who==\"mohameds\"), use_t_maps=use_t_maps)\n",
    "decoder.set_masks_exist(masks_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_voxels = maps_masked[0][\"vis\"][0][\"V5_L\"].shape[1]\n",
    "for name in classifiers:\n",
    "    if isinstance(decoder.models[name].estimator.steps[1][1], SelectKBest): \n",
    "        decoder.models[name].estimator.steps[1][1].set_params(k = k_selector(n_voxels))\n",
    "print(\"initially \"+str(n_voxels)+\" voxels, selected = \"+str(k_selector(n_voxels))+\" voxels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Within-modality decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1/23 done in 227.57413625717163 seconds\n",
      "subject 2/23 done in 446.1944360733032 seconds\n",
      "subject 3/23 done in 613.0493385791779 seconds\n",
      "subject 4/23 done in 856.329986333847 seconds\n",
      "subject 5/23 done in 1088.665104150772 seconds\n",
      "subject 6/23 done in 1301.8827946186066 seconds\n",
      "subject 7/23 done in 1512.4825913906097 seconds\n",
      "subject 8/23 done in 1724.7149147987366 seconds\n",
      "subject 9/23 done in 1939.1268103122711 seconds\n",
      "subject 10/23 done in 2146.771112680435 seconds\n",
      "subject 11/23 done in 2359.4018857479095 seconds\n",
      "subject 12/23 done in 2563.850994825363 seconds\n",
      "subject 13/23 done in 2762.966330051422 seconds\n",
      "subject 14/23 done in 2972.632229566574 seconds\n",
      "subject 15/23 done in 3175.932105064392 seconds\n",
      "subject 16/23 done in 3384.8602752685547 seconds\n",
      "subject 17/23 done in 3617.176152229309 seconds\n",
      "subject 18/23 done in 3835.220465898514 seconds\n",
      "subject 19/23 done in 3995.8625054359436 seconds\n",
      "subject 20/23 done in 4205.297813415527 seconds\n",
      "subject 21/23 done in 4258.922575712204 seconds\n",
      "subject 22/23 done in 4466.128063201904 seconds\n",
      "subject 23/23 done in 4669.424371004105 seconds\n",
      "done in 4669.424371004105 seconds\n"
     ]
    }
   ],
   "source": [
    "confusion_matrixes_within, val_scores_within = decoder.within_modality_decoding(maps_masked, labels, subjects_ids, within_modal_tasks_regions)\n",
    "confusion_matrixes_within = change_confusion_matrixes_org(confusion_matrixes_within, subjects_ids, models.keys())\n",
    "val_scores_within = change_confusion_matrixes_org(val_scores_within, subjects_ids, models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cross-modal decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1/23 done in 206.38288974761963 seconds\n",
      "subject 2/23 done in 400.86260294914246 seconds\n",
      "subject 3/23 done in 547.9106330871582 seconds\n",
      "subject 4/23 done in 753.1565067768097 seconds\n",
      "subject 5/23 done in 961.1341166496277 seconds\n",
      "subject 6/23 done in 1172.1722340583801 seconds\n",
      "subject 7/23 done in 1375.2842104434967 seconds\n",
      "subject 8/23 done in 1584.5483627319336 seconds\n",
      "subject 9/23 done in 1809.208894252777 seconds\n",
      "subject 10/23 done in 2022.4113788604736 seconds\n",
      "subject 11/23 done in 2236.3046491146088 seconds\n",
      "subject 12/23 done in 2438.066136598587 seconds\n",
      "subject 13/23 done in 2644.2617440223694 seconds\n",
      "subject 14/23 done in 2856.3597161769867 seconds\n",
      "subject 15/23 done in 3062.58411359787 seconds\n",
      "subject 16/23 done in 3274.8009011745453 seconds\n",
      "subject 17/23 done in 3488.6492404937744 seconds\n",
      "subject 18/23 done in 3701.8641612529755 seconds\n",
      "subject 19/23 done in 3861.0293905735016 seconds\n",
      "subject 20/23 done in 4066.3144931793213 seconds\n",
      "subject 21/23 done in 4117.125281095505 seconds\n",
      "subject 22/23 done in 4322.280571460724 seconds\n",
      "subject 23/23 done in 4523.535165548325 seconds\n",
      "done in 4523.535165548325 seconds\n"
     ]
    }
   ],
   "source": [
    "confusion_matrixes_cross, val_scores_cross = decoder.cross_modality_decoding(maps_masked, labels, subjects_ids, cross_modal_tasks_regions)\n",
    "confusion_matrixes_cross = change_confusion_matrixes_org(confusion_matrixes_cross, subjects_ids, models.keys())\n",
    "val_scores_cross = change_confusion_matrixes_org(val_scores_cross, subjects_ids, models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bootstrapping to assess group-level significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_single_perm = 50\n",
    "n_bootstrap = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "within_cf_100_perm = decoder.score_bootstrapped_permutations(n_single_perm, labels_same, within_modal_tasks_regions,maps_masked,n_subjects, within_modality=True)\n",
    "within_cf_100_perm = change_cfm_bootstrap_org(within_cf_100_perm, subjects_ids, models.keys(), n_single_perm)\n",
    "\n",
    "cross_cf_100_perm = decoder.score_bootstrapped_permutations(n_single_perm, labels_same, cross_modal_tasks_regions,maps_masked,n_subjects, within_modality=False)\n",
    "cross_cf_100_perm = change_cfm_bootstrap_org(cross_cf_100_perm, subjects_ids, models.keys(), n_single_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bootstrapped_distribution_cross = dict()\n",
    "bootstrapped_distribution_within = dict()\n",
    "for name in models.keys():\n",
    "    within_scores_100_perm = compute_accuracy_bootstrap(n_subjects, n_single_perm, within_cf_100_perm[name], len(classes))\n",
    "    bootstrapped_distribution_within[name] = compute_bootstrap_distribution(n_bootstrap, n_subjects, within_scores_100_perm, n_single_perm)\n",
    "\n",
    "    cross_scores_100_perm = compute_accuracy_bootstrap(n_subjects, n_single_perm, cross_cf_100_perm[name], len(classes))\n",
    "    bootstrapped_distribution_cross[name] = compute_bootstrap_distribution(n_bootstrap, n_subjects, cross_scores_100_perm, n_single_perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\metrics.py:46: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall[i] = confusion_matrix[i][i]/sum([confusion_matrix[j][i] for j in range(n_classes)])\n"
     ]
    }
   ],
   "source": [
    "type_maps = \"_t_maps_\" if use_t_maps else \"_beta_maps_\"\n",
    "out_directory = \"out/\"+from_who+type_maps\n",
    "\n",
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction+\"/\"\n",
    "    create_directory(out_dir)\n",
    "    save_dicts(out_dir+\"masks_exist.csv\", masks_exist, list(masks_exist[0].keys()), subjects_ids)\n",
    "    \n",
    "    save_dicts(out_dir+\"confusion_matrixes_within.csv\", confusion_matrixes_within[name], list(confusion_matrixes_within[name][0].keys()), subjects_ids)\n",
    "    save_dicts(out_dir+\"validation_scores_within.csv\", val_scores_within[name], list(val_scores_within[name][0].keys()), subjects_ids)\n",
    "    acc_within = compute_metric(out_dir, subjects_ids, {'name' : 'accuracy', 'function':accuracy}, \"within\", masks_exist, len(classes), ret = True)\n",
    "\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'recall', 'function':recall}, \"within\", masks_exist, len(classes))\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'precision', 'function':precision}, \"within\", masks_exist, len(classes))\n",
    "\n",
    "    within_modality_group_results = average_dicos(acc_within)\n",
    "    save_dicts(out_dir+\"group_scores_within.csv\", [within_modality_group_results], list(within_modality_group_results.keys()), [0])\n",
    "\n",
    "    save_dicts(out_dir+\"confusion_matrixes_cross.csv\", confusion_matrixes_cross[name], list(confusion_matrixes_cross[name][0].keys()), subjects_ids)\n",
    "    save_dicts(out_dir+\"validation_scores_cross.csv\", val_scores_cross[name], list(val_scores_cross[name][0].keys()), subjects_ids)\n",
    "    acc_cross = compute_metric(out_dir, subjects_ids, {'name' : 'accuracy', 'function':accuracy}, \"cross\", masks_exist, len(classes), ret = True)\n",
    "    \n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'recall', 'function':recall}, \"cross\", masks_exist, len(classes))\n",
    "    compute_metric(out_dir, subjects_ids, {'name' : 'precision', 'function':precision}, \"cross\", masks_exist, len(classes))\n",
    "\n",
    "    cross_modality_group_results = average_dicos(acc_cross)\n",
    "    save_dicts(out_dir+\"group_scores_cross.csv\", [cross_modality_group_results], list(cross_modality_group_results.keys()), [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+\"/\"\n",
    "    save_dicts(out_dir+\"accuracy_bootstraps_within.csv\", [bootstrapped_distribution_within[name]], list(bootstrapped_distribution_within[name][0].keys()), range(n_bootstrap))\n",
    "    save_dicts(out_dir+\"accuracy_bootstraps_cross.csv\", [bootstrapped_distribution_cross[name]], list(bootstrapped_distribution_cross[name][0].keys()), range(n_bootstrap))\n",
    "\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    bootstrap_df  = retrieve_bootstrap_metric(out_dir, \"accuracy\")\n",
    "    pvals = compute_p_val_bootstrap(bootstrap_df, cv_group_df)\n",
    "    save_dicts(out_dir+\"estimated_pval_bootstrap.csv\", [pvals], list(pvals.keys()), [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results (from files of saved results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No p-values found in directory : out/our_t_maps_SVC(random_state=0)_3_radius=10_Tcorrected/\n",
      "No p-values found in directory : out/our_t_maps_LogisticRegression(random_state=0)_3_radius=10_Tcorrected/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No p-values found in directory : out/our_t_maps_KNeighborsClassifier()_3_radius=10_Tcorrected/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:259: RuntimeWarning: Mean of empty slice\n",
      "  score_per_analysis[analysis][key] = np.nanmean(tab, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No p-values found in directory : out/our_t_maps_Perceptron()_3_radius=10_Tcorrected/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\miniconda3\\lib\\site-packages\\seaborn\\axisgrid.py:409: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=figsize)\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:259: RuntimeWarning: Mean of empty slice\n",
      "  score_per_analysis[analysis][key] = np.nanmean(tab, axis=0)\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:275: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 8))\n",
      "C:\\Users\\nicol\\OneDrive\\Bureau\\Mémoire\\MasterThesisGit\\plots.py:212: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  pylab.figure(figsize=(8, 8))\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1656x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1656x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1656x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1656x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_maps = \"_t_maps_\" if use_t_maps else \"_beta_maps_\"\n",
    "out_directory = \"out/\"+from_who+type_maps\n",
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction+\"/\"\n",
    "    masks_exist = retrieve_masks_exist(out_dir)\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    cv_df = retrieve_cv_metric(out_dir, \"accuracy\")\n",
    "    cfm_df = retrieve_cv_matrixes(out_dir)\n",
    "    val_scores_df = retrieve_val_scores(out_dir)\n",
    "    pvals = retrieve_pvals(out_dir, default_keys=cv_df.columns)\n",
    "\n",
    "    plt_dir = \"plots/\"+from_who+type_maps+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+correction\n",
    "    create_directory(plt_dir)\n",
    "    plotter = Plotter(plt_dir, subjects_ids)\n",
    "    plotter.plot_cv_score_with_points(cv_df, pvals, chance_level = True)\n",
    "    plotter.plot_validation_scores_hyper_param(val_scores_df, \"C\", param_grids[\"svm\"][\"svm__C\"], masks_exist, chance_level=True, log10_scale=True)\n",
    "\n",
    "    group_cfm = compute_group_confusion_matrix(cfm_df, subjects_ids)\n",
    "    plotter.plot_group_confusion_matrix(group_cfm, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for name in classifiers:\n",
    "    out_dir = out_directory+str(classifiers[name])+\"_\"+voxel_size+\"_radius=\"+radius_mask+\"/\"\n",
    "    bootstrap_df  = retrieve_bootstrap_metric(out_dir, \"accuracy\")\n",
    "    cv_group_df = retrieve_cv_metric(out_dir, \"group_scores\")\n",
    "    pvals = retrieve_pvals(out_dir)\n",
    "    \n",
    "    plotter.plot_bootstrap(bootstrap_df, cv_group_df, pvals, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2880x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 2880x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subjects_ids = range(1,24)\n",
    "out_folders = [\"out/our_t_maps_SVC(random_state=0)_3_radius=10_Tcorrected/\",\n",
    "               \"out/our_t_maps_LogisticRegression(random_state=0)_3_radius=10_Tcorrected/\",\n",
    "               \"out/our_t_maps_KNeighborsClassifier()_3_radius=10_Tcorrected/\",\n",
    "               \"out/our_t_maps_Perceptron()_3_radius=10_Tcorrected/\",\n",
    "               ]\n",
    "classifiers_names = [\"SVM\", \"LR\", \"KNN\", \"Perceptron\"]\n",
    "plotter = Plotter(\"plots/comparing_classifiers_\"+\"_\".join(classifiers_names), subjects_ids)\n",
    "plotter.plot_tests_scores_from_different_folders(out_folders, classifiers_names, \"Comparing classifiers\", \"Classifier\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}